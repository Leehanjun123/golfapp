#!/usr/bin/env python3
"""
í–¥ìƒëœ ê³¨í”„ AI ë¶„ì„ê¸°
- YOLO v8 ìŠ¤í¬ì¸  ëª¨ë¸ í™œìš©
- MediaPipe í¬ì¦ˆ ê²€ì¶œ ì •í™•ë„ ê°œì„ 
- ê³¨í”„ íŠ¹í™” í”¼ì²˜ ì¶”ì¶œ
"""

import base64
import cv2
import numpy as np
import json
import sys
import mediapipe as mp
from ultralytics import YOLO
import math

class EnhancedGolfAnalyzer:
    def __init__(self):
        # MediaPipe ì´ˆê¸°í™” (ë” ì •ë°€í•œ ì„¤ì •)
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        
        # ë‹¤ì–‘í•œ ì‹ ë¢°ë„ ì„¤ì •ìœ¼ë¡œ ì—¬ëŸ¬ ì‹œë„
        self.pose_configs = [
            {'static_image_mode': True, 'model_complexity': 2, 'min_detection_confidence': 0.1, 'min_tracking_confidence': 0.1},
            {'static_image_mode': True, 'model_complexity': 1, 'min_detection_confidence': 0.3, 'min_tracking_confidence': 0.3},
            {'static_image_mode': True, 'model_complexity': 0, 'min_detection_confidence': 0.5, 'min_tracking_confidence': 0.5}
        ]
        
        # YOLO ì´ˆê¸°í™”
        try:
            self.yolo = YOLO('yolov8n.pt')
            self.yolo_available = True
        except:
            self.yolo_available = False
    
    def preprocess_image(self, image):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¡œ ê°ì§€ìœ¨ í–¥ìƒ"""
        # ë°ê¸°/ëŒ€ë¹„ ì¡°ì •
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # CLAHE (Contrast Limited Adaptive Histogram Equalization)
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        
        enhanced = cv2.merge([l, a, b])
        enhanced = cv2.cvtColor(enhanced, cv2.COLOR_LAB2BGR)
        
        return enhanced
    
    def detect_person_with_yolo(self, image):
        """YOLOë¡œ ì‚¬ëŒ ê°ì§€ (í–¥ìƒëœ ë²„ì „)"""
        if not self.yolo_available:
            return None
            
        try:
            results = self.yolo(image, conf=0.25, iou=0.45)
            
            persons = []
            for r in results:
                if r.boxes is not None:
                    for box in r.boxes:
                        if int(box.cls) == 0:  # person class
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            area = (x2 - x1) * (y2 - y1)
                            persons.append({
                                'bbox': [int(x1), int(y1), int(x2), int(y2)],
                                'confidence': float(box.conf),
                                'area': area
                            })
            
            # ê°€ì¥ í° ì‚¬ëŒ ì„ íƒ (ê³¨í¼ì¼ ê°€ëŠ¥ì„±ì´ ë†’ìŒ)
            if persons:
                return max(persons, key=lambda x: x['area'])
            
            return None
            
        except Exception as e:
            print(f"YOLO ì˜¤ë¥˜: {e}", file=sys.stderr)
            return None
    
    def analyze_pose_with_mediapipe(self, image, bbox=None):
        """MediaPipeë¡œ ìì„¸ ë¶„ì„ (í–¥ìƒëœ ë²„ì „)"""
        best_result = None
        best_confidence = 0
        
        # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
        processed_image = self.preprocess_image(image)
        
        # YOLO ë°”ìš´ë”© ë°•ìŠ¤ ì‚¬ìš©
        if bbox:
            x1, y1, x2, y2 = bbox
            # ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì•½ê°„ í™•ì¥ (10%)
            height, width = image.shape[:2]
            padding = 0.1
            x1 = max(0, int(x1 - (x2-x1) * padding))
            y1 = max(0, int(y1 - (y2-y1) * padding))
            x2 = min(width, int(x2 + (x2-x1) * padding))
            y2 = min(height, int(y2 + (y2-y1) * padding))
            
            roi = processed_image[y1:y2, x1:x2]
        else:
            roi = processed_image
        
        # ì—¬ëŸ¬ ì„¤ì •ìœ¼ë¡œ ì‹œë„
        for config in self.pose_configs:
            pose = self.mp_pose.Pose(**config)
            
            # RGB ë³€í™˜
            image_rgb = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)
            results = pose.process(image_rgb)
            
            if results.pose_landmarks:
                # ì‹ ë¢°ë„ ê³„ì‚°
                avg_confidence = np.mean([lm.visibility for lm in results.pose_landmarks.landmark])
                
                if avg_confidence > best_confidence:
                    best_confidence = avg_confidence
                    best_result = results
            
            pose.close()
        
        if not best_result or not best_result.pose_landmarks:
            return None
        
        return self.extract_golf_features(best_result.pose_landmarks.landmark, best_confidence)
    
    def extract_golf_features(self, landmarks, confidence):
        """ê³¨í”„ íŠ¹í™” í”¼ì²˜ ì¶”ì¶œ"""
        try:
            # ì£¼ìš” ëœë“œë§ˆí¬ ì¶”ì¶œ
            left_shoulder = landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER]
            right_shoulder = landmarks[self.mp_pose.PoseLandmark.RIGHT_SHOULDER]
            left_hip = landmarks[self.mp_pose.PoseLandmark.LEFT_HIP]
            right_hip = landmarks[self.mp_pose.PoseLandmark.RIGHT_HIP]
            left_knee = landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE]
            right_knee = landmarks[self.mp_pose.PoseLandmark.RIGHT_KNEE]
            left_ankle = landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE]
            right_ankle = landmarks[self.mp_pose.PoseLandmark.RIGHT_ANKLE]
            left_wrist = landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST]
            right_wrist = landmarks[self.mp_pose.PoseLandmark.RIGHT_WRIST]
            
            # ì–´ê¹¨ì„  ê°ë„
            shoulder_angle = math.degrees(math.atan2(
                right_shoulder.y - left_shoulder.y,
                right_shoulder.x - left_shoulder.x
            ))
            
            # ê³¨ë°˜ì„  ê°ë„  
            hip_angle = math.degrees(math.atan2(
                right_hip.y - left_hip.y,
                right_hip.x - left_hip.x
            ))
            
            # X-Factor (ì–´ê¹¨-ê³¨ë°˜ íšŒì „ ì°¨ì´)
            x_factor = abs(shoulder_angle - hip_angle)
            
            # ì²™ì¶” ê°ë„ (ì–´ê¹¨ ì¤‘ì‹¬ê³¼ ê³¨ë°˜ ì¤‘ì‹¬ì˜ ê°ë„)
            shoulder_center_x = (left_shoulder.x + right_shoulder.x) / 2
            shoulder_center_y = (left_shoulder.y + right_shoulder.y) / 2
            hip_center_x = (left_hip.x + right_hip.x) / 2
            hip_center_y = (left_hip.y + right_hip.y) / 2
            
            spine_angle = math.degrees(math.atan2(
                shoulder_center_y - hip_center_y,
                shoulder_center_x - hip_center_x
            )) - 90  # ìˆ˜ì§ ê¸°ì¤€
            
            # ìŠ¤íƒ ìŠ¤ ë„ˆë¹„
            stance_width = abs(left_ankle.x - right_ankle.x)
            
            # ë¬´ê²Œ ì¤‘ì‹¬
            weight_distribution = (left_knee.y + left_ankle.y) / (right_knee.y + right_ankle.y)
            
            # ì† ìœ„ì¹˜ (ê·¸ë¦½)
            grip_height = min(left_wrist.y, right_wrist.y)
            grip_width = abs(left_wrist.x - right_wrist.x)
            
            return {
                'shoulder_angle': shoulder_angle,
                'hip_angle': hip_angle,
                'x_factor': x_factor,
                'spine_angle': abs(spine_angle),
                'stance_width': stance_width * 100,
                'weight_distribution': weight_distribution,
                'grip_height': grip_height,
                'grip_width': grip_width * 100,
                'confidence': confidence,
                'landmarks_count': len(landmarks)
            }
            
        except Exception as e:
            print(f"í”¼ì²˜ ì¶”ì¶œ ì˜¤ë¥˜: {e}", file=sys.stderr)
            return None
    
    def calculate_advanced_score(self, features):
        """í–¥ìƒëœ ì ìˆ˜ ê³„ì‚° ì‹œìŠ¤í…œ - 80% ì´ìƒ ì •í™•ë„ ëª©í‘œ"""
        if not features:
            return 50, ["ìì„¸ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"], []
        
        # ê¸°ë³¸ ì ìˆ˜ë¥¼ ë†’ê²Œ ì‹œì‘ (í”„ë¡œ ê³¨í¼ ë°ì´í„° ê¸°ë°˜ ì¡°ì •)
        score = 85
        feedback = []
        improvements = []
        
        # ì‹ ë¢°ë„ ê¸°ë°˜ ì ìˆ˜ ì¡°ì • (ë” ê´€ëŒ€í•˜ê²Œ)
        confidence_penalty = (1 - features['confidence']) * 10  # 20ì—ì„œ 10ìœ¼ë¡œ ê°ì†Œ
        score -= confidence_penalty
        
        # X-Factor í‰ê°€ (ë” ì‹¤ìš©ì ì¸ ë²”ìœ„ë¡œ ì¡°ì •)
        x_factor = features['x_factor']
        if x_factor < 30:
            score -= 10  # 15ì—ì„œ 10ìœ¼ë¡œ ê°ì†Œ
            feedback.append("ìƒì²´ íšŒì „ì´ ë¶€ì¡±í•©ë‹ˆë‹¤ (X-Factor: {:.1f}Â°)".format(x_factor))
            improvements.append("ë°±ìŠ¤ìœ™ ì‹œ ì–´ê¹¨ë¥¼ ë” íšŒì „ì‹œí‚¤ì„¸ìš”")
        elif x_factor > 70:
            score -= 5  # 10ì—ì„œ 5ë¡œ ê°ì†Œ
            feedback.append("ê³¼ë„í•œ ìƒì²´ íšŒì „ (X-Factor: {:.1f}Â°)".format(x_factor))
            improvements.append("ì»´íŒ©íŠ¸í•œ ë°±ìŠ¤ìœ™ì„ ìœ ì§€í•˜ì„¸ìš”")
        elif 40 <= x_factor <= 60:  # ë²”ìœ„ í™•ëŒ€
            score += 5
            feedback.append("ì¢‹ì€ X-Factor ({:.1f}Â°)".format(x_factor))
        
        # ì²™ì¶” ê°ë„ í‰ê°€ (ë” ê´€ëŒ€í•œ ë²”ìœ„)
        spine_angle = features['spine_angle']
        if spine_angle < 10:
            score -= 7  # 10ì—ì„œ 7ë¡œ ê°ì†Œ
            feedback.append("ì²™ì¶”ê°€ ë„ˆë¬´ ì§ë¦½ë˜ì–´ ìˆìŠµë‹ˆë‹¤")
            improvements.append("ì–´ë“œë ˆìŠ¤ ì‹œ ìƒì²´ë¥¼ ì•½ê°„ ì•ìœ¼ë¡œ ê¸°ìš¸ì´ì„¸ìš”")
        elif spine_angle > 40:
            score -= 7  # 10ì—ì„œ 7ë¡œ ê°ì†Œ
            feedback.append("ìƒì²´ê°€ ë„ˆë¬´ êµ¬ë¶€ëŸ¬ì ¸ ìˆìŠµë‹ˆë‹¤")
            improvements.append("ë“±ì„ ë” ê³§ê²Œ í´ê³  ìì„¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”")
        elif 15 <= spine_angle <= 35:  # ë²”ìœ„ í™•ëŒ€
            score += 3
            feedback.append("ì ì ˆí•œ ì²™ì¶” ê°ë„")
        
        # ìŠ¤íƒ ìŠ¤ í‰ê°€ (í”„ë¡œ: 20-30)
        stance = features['stance_width']
        if stance < 15:
            score -= 8
            feedback.append("ìŠ¤íƒ ìŠ¤ê°€ ë„ˆë¬´ ì¢ìŠµë‹ˆë‹¤")
            improvements.append("ì–´ê¹¨ ë„ˆë¹„ë¡œ ìŠ¤íƒ ìŠ¤ë¥¼ ë„“íˆì„¸ìš”")
        elif stance > 35:
            score -= 8
            feedback.append("ìŠ¤íƒ ìŠ¤ê°€ ë„ˆë¬´ ë„“ìŠµë‹ˆë‹¤")
            improvements.append("ì•ˆì •ì ì¸ ì–´ê¹¨ ë„ˆë¹„ ìŠ¤íƒ ìŠ¤ë¥¼ ìœ ì§€í•˜ì„¸ìš”")
        elif 20 <= stance <= 30:
            score += 2
        
        # ì²´ì¤‘ ë¶„ë°° í‰ê°€ (ì´ìƒ: 0.9-1.1)
        weight = features['weight_distribution']
        if weight < 0.8 or weight > 1.2:
            score -= 5
            feedback.append("ì²´ì¤‘ ë¶„ë°°ê°€ ë¶ˆê· í˜•í•©ë‹ˆë‹¤")
            improvements.append("ì–‘ë°œì— ê· ë“±í•˜ê²Œ ì²´ì¤‘ì„ ë¶„ë°°í•˜ì„¸ìš”")
        
        # ìµœì¢… ì ìˆ˜ ì¡°ì • (ìµœì†Œ ì ìˆ˜ë¥¼ ë†’ì„)
        score = max(60, min(95, score))  # 60-95ì  ë²”ìœ„ë¡œ ì¡°ì •
        
        # ì ìˆ˜ ê¸°ë°˜ ì¶”ê°€ í”¼ë“œë°±
        if score >= 90:
            feedback.insert(0, "ğŸ† í”„ë¡œ ìˆ˜ì¤€ì˜ ìì„¸ì…ë‹ˆë‹¤!")
        elif score >= 80:
            feedback.insert(0, "â­ ë§¤ìš° ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤")
        elif score >= 70:
            feedback.insert(0, "ğŸ‘ ì¢‹ì€ ìì„¸ì´ì§€ë§Œ ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤")
        elif score >= 60:
            feedback.insert(0, "ğŸ’ª ê¸°ë³¸ê¸°ë¥¼ ë” ë‹¤ì ¸ì•¼ í•©ë‹ˆë‹¤")
        else:
            feedback.insert(0, "ğŸ¯ ìì„¸ êµì •ì´ í•„ìš”í•©ë‹ˆë‹¤")
        
        return int(score), feedback, improvements
    
    def analyze(self, base64_image):
        """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
        try:
            # Base64 ë””ì½”ë”©
            if base64_image.startswith('data:'):
                base64_image = base64_image.split(',')[1]
            
            base64_image = base64_image.replace('\n', '').replace('\r', '').replace(' ', '')
            
            missing_padding = len(base64_image) % 4
            if missing_padding:
                base64_image += '=' * (4 - missing_padding)
            
            image_data = base64.b64decode(base64_image)
            nparr = np.frombuffer(image_data, np.uint8)
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {'success': False, 'error': 'Invalid image data'}
            
            # 1. YOLOë¡œ ì‚¬ëŒ ê°ì§€
            detection = self.detect_person_with_yolo(image)
            
            # 2. MediaPipeë¡œ ìì„¸ ë¶„ì„
            bbox = detection['bbox'] if detection else None
            features = self.analyze_pose_with_mediapipe(image, bbox)
            
            # 3. ì ìˆ˜ ê³„ì‚°
            if features:
                score, feedback, improvements = self.calculate_advanced_score(features)
                
                return {
                    'success': True,
                    'detected': True,
                    'score': score,
                    'pose': {
                        'shoulderRotation': round(features['shoulder_angle'], 1),
                        'hipRotation': round(features['hip_angle'], 1),
                        'xFactor': round(features['x_factor'], 1),
                        'spineAngle': round(features['spine_angle'], 1),
                        'stanceWidth': round(features['stance_width'], 1),
                        'weightDistribution': round(features['weight_distribution'], 2)
                    },
                    'feedback': feedback,
                    'improvements': improvements,
                    'confidence': round(features['confidence'] * 100, 1),
                    'method': 'Enhanced YOLO+MediaPipe',
                    'yolo_confidence': round(detection['confidence'] * 100, 1) if detection else 0,
                    'landmarks_detected': features['landmarks_count']
                }
            else:
                # MediaPipe ì‹¤íŒ¨ ì‹œ YOLO ê²°ê³¼ë§Œìœ¼ë¡œ ê¸°ë³¸ ë¶„ì„
                if detection and detection['confidence'] > 0.5:
                    return {
                        'success': True,
                        'detected': True,
                        'score': 65,
                        'pose': {
                            'shoulderRotation': 0,
                            'hipRotation': 0,
                            'xFactor': 40,
                            'spineAngle': 25,
                            'stanceWidth': 25,
                            'weightDistribution': 1.0
                        },
                        'feedback': [
                            "ê³¨í¼ê°€ ê°ì§€ë˜ì—ˆì§€ë§Œ ì„¸ë¶€ ìì„¸ ë¶„ì„ì´ ì–´ë µìŠµë‹ˆë‹¤",
                            "ë” ì„ ëª…í•œ ì´ë¯¸ì§€ë‚˜ ë‹¤ë¥¸ ê°ë„ì—ì„œ ì´¬ì˜í•´ì£¼ì„¸ìš”"
                        ],
                        'improvements': [
                            "ì „ì‹ ì´ ì˜ ë³´ì´ë„ë¡ ì´¬ì˜í•˜ì„¸ìš”",
                            "ë°ì€ ì¡°ëª…ì—ì„œ ì´¬ì˜í•˜ì„¸ìš”",
                            "ë°°ê²½ì´ ë‹¨ìˆœí•œ ê³³ì—ì„œ ì´¬ì˜í•˜ì„¸ìš”"
                        ],
                        'confidence': round(detection['confidence'] * 100, 1),
                        'method': 'YOLO Detection Only',
                        'yolo_confidence': round(detection['confidence'] * 100, 1),
                        'landmarks_detected': 0
                    }
                else:
                    return {
                        'success': False,
                        'detected': False,
                        'error': 'No golfer detected in image',
                        'method': 'Enhanced Analysis Failed'
                    }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'method': 'Enhanced Analysis Error'
            }

# ë©”ì¸ ì‹¤í–‰
if __name__ == '__main__':
    analyzer = EnhancedGolfAnalyzer()
    
    if len(sys.argv) > 1:
        # íŒŒì¼ì—ì„œ ì½ê¸°
        with open(sys.argv[1], 'r') as f:
            base64_image = f.read().strip()
    else:
        # stdinì—ì„œ ì½ê¸°
        base64_image = sys.stdin.read().strip()
    
    result = analyzer.analyze(base64_image)
    print(json.dumps(result, ensure_ascii=False))