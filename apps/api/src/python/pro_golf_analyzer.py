#!/usr/bin/env python3
"""
í”„ë¡œ ìˆ˜ì¤€ ê³¨í”„ AI ë¶„ì„ê¸°
- ì •í™•ë„ 80% ì´ìƒ ëª©í‘œ
- ê³¨í”„ ì „ìš© ìµœì í™”
"""

import base64
import cv2
import numpy as np
import json
import sys
import mediapipe as mp
from ultralytics import YOLO
import math

class ProGolfAnalyzer:
    def __init__(self):
        # MediaPipe ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        
        # ê³¨í”„ ìì„¸ ê°ì§€ë¥¼ ìœ„í•œ ìµœì í™”ëœ ì„¤ì • - ì‹¤ì œ ì‚¬ì§„ ìµœì í™”
        self.pose = self.mp_pose.Pose(
            static_image_mode=True,
            model_complexity=2,  # ìµœê³  ë³µì¡ë„
            min_detection_confidence=0.1,  # ë§¤ìš° ê´€ëŒ€í•œ ê°ì§€ (0.3 â†’ 0.1)
            min_tracking_confidence=0.1,   # ë§¤ìš° ê´€ëŒ€í•œ ì¶”ì  (0.3 â†’ 0.1)
            enable_segmentation=True,  # ì„¸ê·¸ë©˜í…Œì´ì…˜ í™œì„±í™”
            smooth_segmentation=True
        )
        
        # ë¹„ë””ì˜¤ ë¶„ì„ìš© ì¶”ê°€ ì„¤ì •
        self.pose_video = self.mp_pose.Pose(
            static_image_mode=False,  # ë¹„ë””ì˜¤ ëª¨ë“œ
            model_complexity=1,       # ì„±ëŠ¥ ìµœì í™”
            min_detection_confidence=0.1,
            min_tracking_confidence=0.1,
            enable_segmentation=False,  # ë¹„ë””ì˜¤ëŠ” ì„¸ê·¸ë©˜í…Œì´ì…˜ ë”
            smooth_segmentation=False
        )
        
        # YOLO ì´ˆê¸°í™”
        try:
            self.yolo = YOLO('yolov8n.pt')
            self.yolo_available = True
        except:
            self.yolo_available = False
        
        # ê³¨í”„ ìŠ¤ìœ™ ë‹¨ê³„ë³„ ì´ìƒì ì¸ ê°ë„ (PGA í”„ë¡œ ë°ì´í„° ê¸°ë°˜)
        self.ideal_angles = {
            'address': {
                'spine_tilt': 25,  # ì²™ì¶” ê¸°ìš¸ê¸°
                'knee_flex': 25,   # ë¬´ë¦ êµ½í˜
                'hip_bend': 30,    # ì—‰ë©ì´ êµ½í˜
                'shoulder_tilt': 5  # ì–´ê¹¨ ê¸°ìš¸ê¸°
            },
            'backswing': {
                'shoulder_rotation': 90,  # ì–´ê¹¨ íšŒì „
                'hip_rotation': 45,       # ì—‰ë©ì´ íšŒì „
                'x_factor': 45,          # X-Factor
                'wrist_hinge': 90        # ì†ëª© ì½”í‚¹
            },
            'downswing': {
                'hip_lead': 30,          # ì—‰ë©ì´ ë¦¬ë“œ
                'lag_angle': 90,         # ë˜ê·¸ ê°ë„
                'shoulder_drop': 10      # ì–´ê¹¨ ë“œë¡­
            },
            'impact': {
                'shaft_lean': 10,        # ìƒ¤í”„íŠ¸ ê¸°ìš¸ê¸°
                'hip_open': 45,          # ì—‰ë©ì´ ì˜¤í”ˆ
                'shoulder_square': 0     # ì–´ê¹¨ ì •ë ¬
            }
        }
    
    def preprocess_image(self, image):
        """ì‹¤ì œ ì‚¬ì§„ ë¶„ì„ì„ ìœ„í•œ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        # 1. ì´ë¯¸ì§€ í¬ê¸° ì²´í¬ ë° ë¦¬ì‚¬ì´ì¦ˆ
        h, w = image.shape[:2]
        print(f"ğŸ–¼ï¸ ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°: {w}x{h}", file=sys.stderr)
        
        # ë„ˆë¬´ ì‘ì€ ì´ë¯¸ì§€ (300px ë¯¸ë§Œ) í™•ëŒ€
        if min(w, h) < 300:
            scale = 300 / min(w, h)
            new_w, new_h = int(w * scale), int(h * scale)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_CUBIC)
            print(f"ğŸ“ˆ ì´ë¯¸ì§€ í™•ëŒ€: {new_w}x{new_h} (scale: {scale:.2f})", file=sys.stderr)
        
        # ë„ˆë¬´ í° ì´ë¯¸ì§€ (2000px ì´ˆê³¼) ì¶•ì†Œ
        elif max(w, h) > 2000:
            scale = 2000 / max(w, h)
            new_w, new_h = int(w * scale), int(h * scale)
            image = cv2.resize(image, (new_w, new_h), interpolation=cv2.INTER_AREA)
            print(f"ğŸ“‰ ì´ë¯¸ì§€ ì¶•ì†Œ: {new_w}x{new_h} (scale: {scale:.2f})", file=sys.stderr)
        
        # 2. ëŒ€ë¹„ ë° ë°ê¸° ì¡°ì • (CLAHE - Contrast Limited Adaptive Histogram Equalization)
        lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
        l, a, b = cv2.split(lab)
        
        # L ì±„ë„ì— CLAHE ì ìš©
        clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
        l = clahe.apply(l)
        
        # ì´ë¯¸ì§€ ì¬ê²°í•©
        image = cv2.merge([l, a, b])
        image = cv2.cvtColor(image, cv2.COLOR_LAB2BGR)
        
        # 3. ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ë¡œ ë…¸ì´ì¦ˆ ì œê±°
        image = cv2.GaussianBlur(image, (3, 3), 0)
        
        print("âœ¨ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ: í¬ê¸°ì¡°ì • + ëŒ€ë¹„ê°œì„  + ë…¸ì´ì¦ˆì œê±°", file=sys.stderr)
        return image
    
    def analyze_video_frame(self, frame):
        """ë¹„ë””ì˜¤ í”„ë ˆì„ ë¶„ì„ (ìµœì í™”ëœ ì„¤ì •)"""
        try:
            # RGB ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            results = self.pose_video.process(frame_rgb)
            
            if not results.pose_landmarks:
                return None
            
            landmarks = results.pose_landmarks.landmark
            
            # ê¸°ë³¸ ê³¨í”„ ìì„¸ íŠ¹ì§•ë§Œ ì¶”ì¶œ (ì†ë„ ìµœì í™”)
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            left_hip = landmarks[23]
            right_hip = landmarks[24]
            
            # ì–´ê¹¨ íšŒì „ê°
            shoulder_dx = right_shoulder.x - left_shoulder.x
            shoulder_dy = right_shoulder.y - left_shoulder.y
            shoulder_rotation = math.degrees(math.atan2(shoulder_dy, shoulder_dx))
            
            # ì—‰ë©ì´ íšŒì „ê°
            hip_dx = right_hip.x - left_hip.x
            hip_dy = right_hip.y - left_hip.y
            hip_rotation = math.degrees(math.atan2(hip_dy, hip_dx))
            
            # X-Factor
            x_factor = abs(shoulder_rotation - hip_rotation)
            
            # ì‹ ë¢°ë„
            avg_visibility = np.mean([lm.visibility for lm in landmarks])
            
            return {
                'shoulder_rotation': shoulder_rotation,
                'hip_rotation': hip_rotation,
                'x_factor': x_factor,
                'confidence': avg_visibility,
                'frame_valid': True
            }
            
        except Exception as e:
            print(f"í”„ë ˆì„ ë¶„ì„ ì˜¤ë¥˜: {e}", file=sys.stderr)
            return None
    
    def detect_person(self, image):
        """YOLOë¡œ ì‚¬ëŒ ê°ì§€"""
        if not self.yolo_available:
            return None
            
        try:
            results = self.yolo(image, conf=0.3)
            
            for r in results:
                if r.boxes is not None:
                    for box in r.boxes:
                        if int(box.cls) == 0:  # person
                            x1, y1, x2, y2 = box.xyxy[0].tolist()
                            return {
                                'bbox': [int(x1), int(y1), int(x2), int(y2)],
                                'confidence': float(box.conf)
                            }
            return None
        except Exception as e:
            return None
    
    def calculate_angle_3points(self, p1, p2, p3):
        """3ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
        v1 = np.array([p1.x - p2.x, p1.y - p2.y])
        v2 = np.array([p3.x - p2.x, p3.y - p2.y])
        
        cosine = np.dot(v1, v2) / (np.linalg.norm(v1) * np.linalg.norm(v2) + 1e-6)
        angle = np.arccos(np.clip(cosine, -1, 1))
        
        return math.degrees(angle)
    
    def analyze_golf_pose(self, image):
        """ê³¨í”„ ìì„¸ ì •ë°€ ë¶„ì„"""
        try:
            # RGB ë³€í™˜
            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            results = self.pose.process(image_rgb)
            
            if not results.pose_landmarks:
                return None
            
            landmarks = results.pose_landmarks.landmark
            
            # ì£¼ìš” ëœë“œë§ˆí¬
            nose = landmarks[0]
            left_shoulder = landmarks[11]
            right_shoulder = landmarks[12]
            left_elbow = landmarks[13]
            right_elbow = landmarks[14]
            left_wrist = landmarks[15]
            right_wrist = landmarks[16]
            left_hip = landmarks[23]
            right_hip = landmarks[24]
            left_knee = landmarks[25]
            right_knee = landmarks[26]
            left_ankle = landmarks[27]
            right_ankle = landmarks[28]
            
            # 1. ì–´ê¹¨ íšŒì „ê° (ì •í™•í•œ ê³„ì‚°)
            shoulder_dx = right_shoulder.x - left_shoulder.x
            shoulder_dy = right_shoulder.y - left_shoulder.y
            shoulder_rotation = math.degrees(math.atan2(shoulder_dy, shoulder_dx))
            
            # 2. ì—‰ë©ì´ íšŒì „ê°
            hip_dx = right_hip.x - left_hip.x
            hip_dy = right_hip.y - left_hip.y
            hip_rotation = math.degrees(math.atan2(hip_dy, hip_dx))
            
            # 3. X-Factor (ì–´ê¹¨-ì—‰ë©ì´ íšŒì „ ì°¨ì´)
            x_factor = abs(shoulder_rotation - hip_rotation)
            
            # 4. ì²™ì¶” ê°ë„ (ì˜¬ë°”ë¥¸ ê³„ì‚°)
            mid_shoulder_x = (left_shoulder.x + right_shoulder.x) / 2
            mid_shoulder_y = (left_shoulder.y + right_shoulder.y) / 2
            mid_hip_x = (left_hip.x + right_hip.x) / 2
            mid_hip_y = (left_hip.y + right_hip.y) / 2
            
            # ìˆ˜ì§ì„  ëŒ€ë¹„ ì²™ì¶” ê¸°ìš¸ê¸°
            spine_angle = math.degrees(math.atan2(
                abs(mid_shoulder_x - mid_hip_x),
                abs(mid_hip_y - mid_shoulder_y)
            ))
            
            # 5. ë¬´ë¦ êµ½í˜ ê°ë„
            left_knee_angle = self.calculate_angle_3points(left_hip, left_knee, left_ankle)
            right_knee_angle = self.calculate_angle_3points(right_hip, right_knee, right_ankle)
            avg_knee_flex = 180 - (left_knee_angle + right_knee_angle) / 2
            
            # 6. íŒ”ê¿ˆì¹˜ ê°ë„ (ë°±ìŠ¤ìœ™ ì²´í¬)
            left_elbow_angle = self.calculate_angle_3points(left_shoulder, left_elbow, left_wrist)
            right_elbow_angle = self.calculate_angle_3points(right_shoulder, right_elbow, right_wrist)
            
            # 7. ì²´ì¤‘ ë¶„ë°° (ë°œëª© ìœ„ì¹˜ ê¸°ë°˜)
            weight_distribution = (left_ankle.y + left_knee.y) / (right_ankle.y + right_knee.y + 1e-6)
            
            # 8. ìŠ¤íƒ ìŠ¤ ë„ˆë¹„
            stance_width = abs(left_ankle.x - right_ankle.x) * 100
            
            # 9. ì† ìœ„ì¹˜ (ê·¸ë¦½ ì²´í¬)
            hands_together = abs(left_wrist.x - right_wrist.x) < 0.1
            hand_height = (left_wrist.y + right_wrist.y) / 2
            
            # 10. ë¨¸ë¦¬ ìœ„ì¹˜ (í—¤ë“œì—… ì²´í¬)
            head_stability = abs(nose.x - mid_shoulder_x) < 0.1
            
            # ì‹ ë¢°ë„ ê³„ì‚°
            avg_visibility = np.mean([lm.visibility for lm in landmarks])
            
            return {
                'shoulder_rotation': shoulder_rotation,
                'hip_rotation': hip_rotation,
                'x_factor': x_factor,
                'spine_angle': spine_angle,
                'knee_flex': avg_knee_flex,
                'left_elbow_angle': left_elbow_angle,
                'right_elbow_angle': right_elbow_angle,
                'weight_distribution': weight_distribution,
                'stance_width': stance_width,
                'hands_together': hands_together,
                'hand_height': hand_height,
                'head_stability': head_stability,
                'confidence': avg_visibility
            }
            
        except Exception as e:
            print(f"ë¶„ì„ ì˜¤ë¥˜: {e}", file=sys.stderr)
            return None
    
    def determine_swing_phase(self, features):
        """ìŠ¤ìœ™ ë‹¨ê³„ íŒë³„"""
        if features['hands_together'] and features['hand_height'] > 0.6:
            if features['x_factor'] > 30:
                return 'backswing'
            else:
                return 'address'
        elif features['x_factor'] < 20:
            return 'impact'
        else:
            return 'downswing'
    
    def calculate_pro_score(self, features):
        """í”„ë¡œ ìˆ˜ì¤€ ì ìˆ˜ ê³„ì‚°"""
        if not features:
            return 60, ["ìì„¸ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"], []
        
        # ê¸°ë³¸ ì ìˆ˜ 85ì ì—ì„œ ì‹œì‘ (ê´€ëŒ€í•œ ì±„ì )
        score = 85
        feedback = []
        improvements = []
        
        # ìŠ¤ìœ™ ë‹¨ê³„ íŒë³„
        phase = self.determine_swing_phase(features)
        
        # 1. X-Factor í‰ê°€ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
        x_factor = features['x_factor']
        ideal_x = self.ideal_angles['backswing']['x_factor']
        x_diff = abs(x_factor - ideal_x)
        
        if x_diff <= 5:
            score += 10
            feedback.append(f"âœ¨ ì™„ë²½í•œ X-Factor: {x_factor:.0f}Â°")
        elif x_diff <= 10:
            score += 5
            feedback.append(f"â­ ì¢‹ì€ X-Factor: {x_factor:.0f}Â°")
        elif x_diff <= 20:
            score -= 5
            feedback.append(f"X-Factor ê°œì„  í•„ìš”: {x_factor:.0f}Â° (ì´ìƒ: {ideal_x}Â°)")
        else:
            score -= 10
            improvements.append("ìƒì²´ì™€ í•˜ì²´ íšŒì „ ì°¨ì´ë¥¼ ëŠ˜ë¦¬ì„¸ìš”")
        
        # 2. ì²™ì¶” ê°ë„ í‰ê°€
        spine = features['spine_angle']
        ideal_spine = self.ideal_angles['address']['spine_tilt']
        spine_diff = abs(spine - ideal_spine)
        
        if spine_diff <= 5:
            score += 5
            feedback.append(f"âœ… ì¢‹ì€ ì²™ì¶” ê°ë„: {spine:.0f}Â°")
        elif spine_diff <= 15:
            score -= 3
        else:
            score -= 7
            improvements.append(f"ì²™ì¶” ê°ë„ ì¡°ì •: í˜„ì¬ {spine:.0f}Â° â†’ {ideal_spine}Â°")
        
        # 3. ë¬´ë¦ êµ½í˜ í‰ê°€
        knee = features['knee_flex']
        if 20 <= knee <= 35:
            score += 3
            feedback.append("ì ì ˆí•œ ë¬´ë¦ êµ½í˜")
        elif knee < 15:
            score -= 5
            improvements.append("ë¬´ë¦ì„ ë” êµ½íˆì„¸ìš”")
        elif knee > 40:
            score -= 5
            improvements.append("ë¬´ë¦ì„ ëœ êµ½íˆì„¸ìš”")
        
        # 4. ì²´ì¤‘ ë¶„ë°° í‰ê°€
        weight = features['weight_distribution']
        if 0.9 <= weight <= 1.1:
            score += 3
            feedback.append("ê· í˜•ì¡íŒ ì²´ì¤‘ ë¶„ë°°")
        else:
            score -= 3
            improvements.append("ì²´ì¤‘ì„ ì–‘ë°œì— ê· ë“±í•˜ê²Œ ë¶„ë°°í•˜ì„¸ìš”")
        
        # 5. ë¨¸ë¦¬ ì•ˆì •ì„± (í—¤ë“œì—… ì²´í¬)
        if features['head_stability']:
            score += 2
            feedback.append("ë¨¸ë¦¬ ìœ„ì¹˜ ì•ˆì •ì ")
        else:
            score -= 5
            improvements.append("ë¨¸ë¦¬ë¥¼ ê³ ì •í•˜ì„¸ìš” (í—¤ë“œì—… ì£¼ì˜)")
        
        # 6. ì‹ ë¢°ë„ ë³´ë„ˆìŠ¤
        if features['confidence'] > 0.9:
            score += 5
        elif features['confidence'] > 0.8:
            score += 3
        
        # ìµœì¢… ì ìˆ˜ ì¡°ì • (70-95 ë²”ìœ„)
        score = max(70, min(95, score))
        
        # ì ìˆ˜ë³„ ë“±ê¸‰
        if score >= 90:
            feedback.insert(0, "ğŸ† í”„ë¡œ ìˆ˜ì¤€ì˜ ìì„¸ì…ë‹ˆë‹¤!")
        elif score >= 85:
            feedback.insert(0, "â­ ë§¤ìš° ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤")
        elif score >= 80:
            feedback.insert(0, "ğŸ‘ ì¢‹ì€ ìì„¸ì…ë‹ˆë‹¤")
        elif score >= 75:
            feedback.insert(0, "ğŸ’ª ê°œì„ ì´ í•„ìš”í•˜ì§€ë§Œ ê¸°ë³¸ê¸°ëŠ” ì¢‹ìŠµë‹ˆë‹¤")
        else:
            feedback.insert(0, "ğŸ¯ ê¸°ë³¸ê¸° ê°•í™”ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        # ê°œì„ ì‚¬í•­ì´ ì—†ìœ¼ë©´ ê¸ì •ì  í”¼ë“œë°± ì¶”ê°€
        if not improvements:
            improvements.append("í˜„ì¬ ìì„¸ë¥¼ ìœ ì§€í•˜ë©´ì„œ ì—°ìŠµí•˜ì„¸ìš”")
            improvements.append("ì¼ê´€ì„± ìˆëŠ” ìŠ¤ìœ™ì´ ì¤‘ìš”í•©ë‹ˆë‹¤")
        
        return int(score), feedback, improvements
    
    def detect_swing_faults(self, features):
        """ì‹¤ì œ AI ê¸°ë°˜ ê³¨í”„ ìŠ¤ìœ™ ê²°í•¨ ê°ì§€"""
        faults = []
        
        # X-Factor ì²´í¬
        if features['x_factor'] < 30:
            faults.append({
                'type': 'insufficient_turn',
                'severity': 'medium',
                'message': 'ìƒì²´ íšŒì „ ë¶€ì¡±',
                'fix': 'ì–´ê¹¨ë¥¼ ë” ë§ì´ ëŒë¦¬ì„¸ìš”'
            })
        elif features['x_factor'] > 60:
            faults.append({
                'type': 'over_turn',
                'severity': 'low',
                'message': 'ê³¼ë„í•œ ìƒì²´ íšŒì „',
                'fix': 'ì–´ê¹¨ íšŒì „ì„ ì¤„ì´ì„¸ìš”'
            })
        
        # ì²™ì¶” ê°ë„ ì²´í¬
        if features['spine_angle'] > 35:
            faults.append({
                'type': 'excessive_spine_tilt',
                'severity': 'high',
                'message': 'ê³¼ë„í•œ ì²™ì¶” ê¸°ìš¸ê¸°',
                'fix': 'ìƒì²´ë¥¼ ë” ì„¸ìš°ì„¸ìš”'
            })
        elif features['spine_angle'] < 15:
            faults.append({
                'type': 'insufficient_spine_tilt',
                'severity': 'medium',
                'message': 'ì²™ì¶” ê¸°ìš¸ê¸° ë¶€ì¡±',
                'fix': 'ìƒì²´ë¥¼ ì•½ê°„ ì•ìœ¼ë¡œ ê¸°ìš¸ì´ì„¸ìš”'
            })
        
        # ë¬´ë¦ êµ½í˜ ì²´í¬
        if features['knee_flex'] > 40:
            faults.append({
                'type': 'excessive_knee_flex',
                'severity': 'medium',
                'message': 'ê³¼ë„í•œ ë¬´ë¦ êµ½í˜',
                'fix': 'ë¬´ë¦ì„ ëœ êµ½íˆì„¸ìš”'
            })
        elif features['knee_flex'] < 15:
            faults.append({
                'type': 'insufficient_knee_flex',
                'severity': 'high',
                'message': 'ë¬´ë¦ êµ½í˜ ë¶€ì¡±',
                'fix': 'ë¬´ë¦ì„ ë” êµ½íˆì„¸ìš”'
            })
        
        # ì²´ì¤‘ ë¶„ë°° ì²´í¬
        if features['weight_distribution'] < 0.8:
            faults.append({
                'type': 'weight_left',
                'severity': 'medium',
                'message': 'ì²´ì¤‘ì´ ì™¼ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨',
                'fix': 'ì²´ì¤‘ì„ ì¤‘ì•™ìœ¼ë¡œ ë¶„ë°°í•˜ì„¸ìš”'
            })
        elif features['weight_distribution'] > 1.2:
            faults.append({
                'type': 'weight_right',
                'severity': 'medium',
                'message': 'ì²´ì¤‘ì´ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì¹˜ìš°ì¹¨',
                'fix': 'ì²´ì¤‘ì„ ì¤‘ì•™ìœ¼ë¡œ ë¶„ë°°í•˜ì„¸ìš”'
            })
        
        # ë¨¸ë¦¬ ìœ„ì¹˜ ì²´í¬
        if not features['head_stability']:
            faults.append({
                'type': 'head_movement',
                'severity': 'high',
                'message': 'ë¨¸ë¦¬ ì›€ì§ì„',
                'fix': 'ë¨¸ë¦¬ë¥¼ ê³ ì •í•˜ê³  ìŠ¤ìœ™í•˜ì„¸ìš”'
            })
        
        return faults
    
    def analyze_video(self, base64_video):
        """ë¹„ë””ì˜¤ ë¶„ì„ í•¨ìˆ˜"""
        try:
            # Base64 ë””ì½”ë”©
            if base64_video.startswith('data:'):
                base64_video = base64_video.split(',')[1]
            
            # ëª¨ë“  ê³µë°± ë¬¸ì ì œê±°
            base64_video = base64_video.replace('\n', '').replace('\r', '').replace(' ', '').replace('\t', '')
            
            # Base64 íŒ¨ë”© ìˆ˜ì •
            missing_padding = len(base64_video) % 4
            if missing_padding:
                base64_video += '=' * (4 - missing_padding)
            
            # ë¹„ë””ì˜¤ ë°ì´í„° ë””ì½”ë”©
            video_data = base64.b64decode(base64_video, validate=True)
            
            if len(video_data) == 0:
                return {'success': False, 'error': 'ë¹ˆ ë¹„ë””ì˜¤ ë°ì´í„°'}
            
            print(f"âœ… ë¹„ë””ì˜¤ ë°ì´í„° ë¡œë“œ: {len(video_data)} ë°”ì´íŠ¸", file=sys.stderr)
            
            # ì„ì‹œ íŒŒì¼ì— ë¹„ë””ì˜¤ ì €ì¥
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_video:
                temp_video.write(video_data)
                temp_video_path = temp_video.name
            
            # OpenCVë¡œ ë¹„ë””ì˜¤ ì½ê¸°
            cap = cv2.VideoCapture(temp_video_path)
            
            if not cap.isOpened():
                return {'success': False, 'error': 'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤'}
            
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = cap.get(cv2.CAP_PROP_FPS)
            duration = frame_count / fps if fps > 0 else 0
            
            print(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {frame_count}í”„ë ˆì„, {fps}fps, {duration:.1f}ì´ˆ", file=sys.stderr)
            
            # í”„ë ˆì„ë³„ ë¶„ì„ ê²°ê³¼ ì €ì¥
            frame_results = []
            valid_frames = 0
            
            # 5í”„ë ˆì„ë§ˆë‹¤ ë¶„ì„ (ì„±ëŠ¥ ìµœì í™”)
            frame_interval = max(1, frame_count // 20)  # ìµœëŒ€ 20í”„ë ˆì„ ë¶„ì„
            
            for i in range(0, frame_count, frame_interval):
                cap.set(cv2.CAP_PROP_POS_FRAMES, i)
                ret, frame = cap.read()
                
                if not ret:
                    break
                
                # í”„ë ˆì„ ë¶„ì„
                result = self.analyze_video_frame(frame)
                
                if result and result['frame_valid']:
                    frame_results.append({
                        'frame_number': i,
                        'timestamp': i / fps if fps > 0 else 0,
                        **result
                    })
                    valid_frames += 1
            
            cap.release()
            
            # ì„ì‹œ íŒŒì¼ ì‚­ì œ
            import os
            os.unlink(temp_video_path)
            
            if valid_frames == 0:
                return {
                    'success': False,
                    'error': 'ë¹„ë””ì˜¤ì—ì„œ ê³¨í”„ ìì„¸ë¥¼ ê°ì§€í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤',
                    'message': 'ê³¨í¼ê°€ ëª…í™•íˆ ë³´ì´ëŠ” ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”'
                }
            
            # ë¹„ë””ì˜¤ ì „ì²´ ë¶„ì„ ê²°ê³¼
            avg_x_factor = np.mean([f['x_factor'] for f in frame_results])
            max_x_factor = max([f['x_factor'] for f in frame_results])
            avg_confidence = np.mean([f['confidence'] for f in frame_results])
            
            # ìŠ¤ìœ™ ë‹¨ê³„ ê°ì§€
            swing_phases = []
            for result in frame_results:
                if result['x_factor'] > 30:
                    swing_phases.append('backswing')
                elif result['x_factor'] < 15:
                    swing_phases.append('impact')
                else:
                    swing_phases.append('downswing')
            
            # ìŠ¤ìœ™ ì™„ì„±ë„ ì ìˆ˜
            swing_completeness = len(set(swing_phases)) / 3 * 100  # 3ë‹¨ê³„ ëª¨ë‘ ìˆìœ¼ë©´ 100%
            
            return {
                'success': True,
                'detected': True,
                'video_analysis': True,
                'score': 70 + (avg_confidence * 25),  # 70-95 ë²”ìœ„
                'frame_count': frame_count,
                'analyzed_frames': valid_frames,
                'duration': duration,
                'pose': {
                    'avgXFactor': round(avg_x_factor, 1),
                    'maxXFactor': round(max_x_factor, 1),
                    'swingCompleteness': round(swing_completeness, 1)
                },
                'swing_phases': list(set(swing_phases)),
                'frame_results': frame_results[-5:],  # ë§ˆì§€ë§‰ 5í”„ë ˆì„ë§Œ ë°˜í™˜
                'feedback': [
                    f"âœ… {valid_frames}ê°œ í”„ë ˆì„ì—ì„œ ê³¨í”„ ìì„¸ ê°ì§€ë¨",
                    f"ğŸ“Š í‰ê·  X-Factor: {avg_x_factor:.1f}Â°",
                    f"ğŸ¯ ìŠ¤ìœ™ ì™„ì„±ë„: {swing_completeness:.1f}%"
                ],
                'improvements': [
                    "ë¹„ë””ì˜¤ ë¶„ì„ì„ í†µí•œ ì—°ì† ë™ì‘ í™•ì¸ ì™„ë£Œ",
                    f"ê°ì§€ëœ ìŠ¤ìœ™ ë‹¨ê³„: {', '.join(set(swing_phases))}"
                ],
                'confidence': round(avg_confidence * 100, 1),
                'method': 'Real MediaPipe Video Analysis',
                'isReal': True
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f'ë¹„ë””ì˜¤ ë¶„ì„ ì˜¤ë¥˜: {str(e)}',
                'method': 'Video Analysis Error'
            }
    
    def analyze(self, base64_image):
        """ë©”ì¸ ë¶„ì„ í•¨ìˆ˜"""
        try:
            # Base64 ë””ì½”ë”© ê°•í™”
            if base64_image.startswith('data:'):
                base64_image = base64_image.split(',')[1]
            
            # ëª¨ë“  ê³µë°± ë¬¸ì ì œê±°
            base64_image = base64_image.replace('\n', '').replace('\r', '').replace(' ', '').replace('\t', '')
            
            # Base64 íŒ¨ë”© ìˆ˜ì •
            missing_padding = len(base64_image) % 4
            if missing_padding:
                base64_image += '=' * (4 - missing_padding)
            
            # ì´ë¯¸ì§€ ë°ì´í„° ê²€ì¦ ë° ë””ì½”ë”©
            try:
                image_data = base64.b64decode(base64_image, validate=True)
            except Exception as decode_error:
                return {'success': False, 'error': f'Base64 ë””ì½”ë”© ì‹¤íŒ¨: {str(decode_error)}'}
            
            if len(image_data) == 0:
                return {'success': False, 'error': 'ë¹ˆ ì´ë¯¸ì§€ ë°ì´í„°'}
            
            # NumPy ë°°ì—´ ìƒì„±
            nparr = np.frombuffer(image_data, np.uint8)
            if len(nparr) == 0:
                return {'success': False, 'error': 'ì´ë¯¸ì§€ ë²„í¼ê°€ ë¹„ì–´ìˆìŒ'}
            
            # OpenCVë¡œ ì´ë¯¸ì§€ ë””ì½”ë”©
            image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
            
            if image is None:
                return {'success': False, 'error': 'OpenCV ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨ - ì§€ì›ë˜ì§€ ì•ŠëŠ” í˜•ì‹'}
            
            if image.size == 0:
                return {'success': False, 'error': 'ë””ì½”ë”©ëœ ì´ë¯¸ì§€ê°€ ë¹„ì–´ìˆìŒ'}
            
            print(f"âœ… ì´ë¯¸ì§€ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œ: {image.shape}", file=sys.stderr)
            
            # ì‹¤ì œ ì‚¬ì§„ ìµœì í™”: ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            image = self.preprocess_image(image)
            print(f"ğŸ”§ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ: {image.shape}", file=sys.stderr)
            
            # 1. YOLOë¡œ ì‚¬ëŒ ê°ì§€
            detection = self.detect_person(image)
            
            # 2. ê³¨í”„ ìì„¸ ë¶„ì„
            features = self.analyze_golf_pose(image)
            
            if not features:
                # ì‹¤ì œ AI ê°ì§€ ì‹¤íŒ¨ì‹œ ëª…í™•í•œ ì˜¤ë¥˜
                return {
                    'success': False,
                    'detected': False,
                    'error': 'ì‹¤ì œ AIê°€ ê³¨í”„ ìì„¸ë¥¼ ê°ì§€í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤',
                    'message': 'ëª…í™•í•œ ê³¨í”„ ìì„¸ê°€ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”',
                    'method': 'Pro Golf Analyzer - Real AI Only'
                }
            
            # 3. í”„ë¡œ ìˆ˜ì¤€ ì ìˆ˜ ê³„ì‚°
            score, feedback, improvements = self.calculate_pro_score(features)
            
            # 4. ì‹¤ì œ ê³¨í”„ ìŠ¤ìœ™ ê²°í•¨ ê°ì§€
            faults = self.detect_swing_faults(features)
            
            return {
                'success': True,
                'detected': True,
                'score': score,
                'pose': {
                    'shoulderRotation': round(features['shoulder_rotation'], 1),
                    'hipRotation': round(features['hip_rotation'], 1),
                    'xFactor': round(features['x_factor'], 1),
                    'spineAngle': round(features['spine_angle'], 1),
                    'kneeFlex': round(features['knee_flex'], 1),
                    'weightDistribution': round(features['weight_distribution'], 2),
                    'stanceWidth': round(features['stance_width'], 1)
                },
                'faults': faults,  # ì‹¤ì œ AI ê²°í•¨ ê°ì§€ ê²°ê³¼
                'feedback': feedback,
                'improvements': improvements,
                'confidence': round(features['confidence'] * 100, 1),
                'method': 'Real MediaPipe AI Analysis',
                'yolo_confidence': round(detection['confidence'] * 100, 1) if detection else 0,
                'isReal': True  # ì‹¤ì œ AI ë¶„ì„ í‘œì‹œ
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'method': 'Pro Golf Analyzer Error'
            }

# ë©”ì¸ ì‹¤í–‰
if __name__ == '__main__':
    analyzer = ProGolfAnalyzer()
    
    # ì»¤ë§¨ë“œë¼ì¸ ì¸ì ì²´í¬
    analysis_type = 'image'  # ê¸°ë³¸ê°’
    if len(sys.argv) > 2 and sys.argv[1] == '--video':
        analysis_type = 'video'
        with open(sys.argv[2], 'r') as f:
            base64_data = f.read().strip()
    elif len(sys.argv) > 1:
        if sys.argv[1] == '--video':
            analysis_type = 'video'
            base64_data = sys.stdin.read().strip()
        else:
            with open(sys.argv[1], 'r') as f:
                base64_data = f.read().strip()
    else:
        base64_data = sys.stdin.read().strip()
        # ë°ì´í„° íƒ€ì… ìë™ ê°ì§€
        if base64_data.startswith('data:video/') or 'mp4' in base64_data[:50]:
            analysis_type = 'video'
    
    # ë¶„ì„ ì‹¤í–‰
    if analysis_type == 'video':
        print("ğŸ¬ ë¹„ë””ì˜¤ ë¶„ì„ ëª¨ë“œ", file=sys.stderr)
        result = analyzer.analyze_video(base64_data)
    else:
        print("ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë“œ", file=sys.stderr)
        result = analyzer.analyze(base64_data)
    
    print(json.dumps(result, ensure_ascii=False))